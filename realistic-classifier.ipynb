{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# These are all the libraries that I have used from the beginning of the project to the end of the project.\n",
    "# Some of them may be unnecessary.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Loading the dateset\n",
    "train_directory = '/kaggle/input/realistic-image/train'\n",
    "validation_directory = '/kaggle/input/realistic-image/validation'\n",
    "test_directory = '/kaggle/input/realistic-image/test'\n",
    "\n",
    "train_labels_csv = '/kaggle/input/realistic-image/train.csv'\n",
    "validation_labels_csv = '/kaggle/input/realistic-image/validation.csv'\n",
    "\n",
    "train_labels_df = pd.read_csv(train_labels_csv)\n",
    "validation_labels_df = pd.read_csv(validation_labels_csv)\n",
    "\n",
    "def load_image_and_label(image_path, label, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    return img_array, label\n",
    "\n",
    "def load_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    return img_array\n",
    "\n",
    "def load_dataset(directory, labels_df, target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in labels_df.iterrows():\n",
    "        image_path = os.path.join(directory, f\"{row['image_id']}.png\")\n",
    "        image, label = load_image_and_label(image_path, row['label'], target_size)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def load_test_dataset(directory, target_size):\n",
    "    images = []\n",
    "    filenames = os.listdir(directory)\n",
    "    image_ids = [x.split(\".\")[0] for x in filenames]\n",
    "    for filename in filenames:\n",
    "        image_path = os.path.join(directory, f\"{filename}\")\n",
    "        image = load_image(image_path, target_size)\n",
    "        images.append(image)\n",
    "    return np.array(images), image_ids\n",
    "\n",
    "target_size = (80, 80)\n",
    "\n",
    "train_images, train_labels = load_dataset(train_directory, train_labels_df, target_size)\n",
    "validation_images, validation_labels = load_dataset(validation_directory, validation_labels_df, target_size)\n",
    "test_images, image_ids = load_test_dataset(test_directory, target_size)\n",
    "\n",
    "train_validation_images = np.concatenate((train_images, validation_images))\n",
    "train_validation_labels = np.concatenate((train_labels, validation_labels))\n",
    "\n",
    "def create_model(input_shape=(80, 80, 3), num_classes=3):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=100, validation_data=(validation_images, validation_labels), callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "# Functions to create training history and confusion matrix plots\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'ro', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation ' + 'Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, validation_images, validation_labels, num_classes):\n",
    "    predictions = model.predict(validation_images)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    confusion_mtx = confusion_matrix(validation_labels, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap=\"Reds\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "plot_confusion_matrix(model, validation_images, validation_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Epoch 1/100\n",
    "  3/329 ━━━━━━━━━━━━━━━━━━━━ 18s 58ms/step - accuracy: 0.2431 - loss: 2.5737 \n",
    "W0000 00:00:1718373875.220099     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.4003 - loss: 1.5421\n",
    "W0000 00:00:1718373898.407853     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
    "W0000 00:00:1718373899.445418     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 39s 79ms/step - accuracy: 0.4003 - loss: 1.5415 - val_accuracy: 0.3637 - val_loss: 1.2285 - learning_rate: 0.0010\n",
    "Epoch 2/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 46ms/step - accuracy: 0.5011 - loss: 1.0695 - val_accuracy: 0.4293 - val_loss: 1.3209 - learning_rate: 0.0010\n",
    "Epoch 3/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 46ms/step - accuracy: 0.6162 - loss: 0.8465 - val_accuracy: 0.6160 - val_loss: 0.8849 - learning_rate: 0.0010\n",
    "Epoch 4/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 46ms/step - accuracy: 0.6597 - loss: 0.7602 - val_accuracy: 0.6023 - val_loss: 0.8691 - learning_rate: 0.0010\n",
    "Epoch 5/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.6796 - loss: 0.7139 - val_accuracy: 0.4877 - val_loss: 1.5479 - learning_rate: 0.0010\n",
    "Epoch 6/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.6948 - loss: 0.6853 - val_accuracy: 0.5517 - val_loss: 1.2495 - learning_rate: 0.0010\n",
    "Epoch 7/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7108 - loss: 0.6534 - val_accuracy: 0.5180 - val_loss: 1.5280 - learning_rate: 0.0010\n",
    "Epoch 8/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7011 - loss: 0.6711 - val_accuracy: 0.6953 - val_loss: 0.6876 - learning_rate: 2.0000e-04\n",
    "Epoch 9/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7484 - loss: 0.5776 - val_accuracy: 0.7337 - val_loss: 0.6001 - learning_rate: 2.0000e-04\n",
    "Epoch 10/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7565 - loss: 0.5538 - val_accuracy: 0.7313 - val_loss: 0.5944 - learning_rate: 2.0000e-04\n",
    "Epoch 11/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7707 - loss: 0.5260 - val_accuracy: 0.7260 - val_loss: 0.5962 - learning_rate: 2.0000e-04\n",
    "Epoch 12/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7646 - loss: 0.5181 - val_accuracy: 0.7057 - val_loss: 0.7154 - learning_rate: 2.0000e-04\n",
    "Epoch 13/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.7768 - loss: 0.5029 - val_accuracy: 0.7420 - val_loss: 0.5771 - learning_rate: 2.0000e-04\n",
    "...\n",
    "Epoch 26/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.8577 - loss: 0.3490 - val_accuracy: 0.7487 - val_loss: 0.5769 - learning_rate: 1.0000e-05\n",
    "Epoch 27/100\n",
    "329/329 ━━━━━━━━━━━━━━━━━━━━ 15s 45ms/step - accuracy: 0.8487 - loss: 0.3529 - val_accuracy: 0.7547 - val_loss: 0.5792 - learning_rate: 1.0000e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Accuracy Validation](accuracy_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix](confusion_matrix.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
